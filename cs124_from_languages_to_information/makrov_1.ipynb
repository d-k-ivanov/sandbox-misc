{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "import glob\r\n",
    "import numpy as np\r\n",
    "from numpy.random import choice\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "from random import random\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "corpus = \"\"\r\n",
    "with open(\"./corpuses/shakespeare.txt\", 'r') as f:\r\n",
    "    corpus+=f.read()\r\n",
    "corpus = corpus.replace('\\n',' ')\r\n",
    "corpus = corpus.replace('\\t',' ')\r\n",
    "corpus = corpus.replace('“', ' \" ')\r\n",
    "corpus = corpus.replace('”', ' \" ')\r\n",
    "for spaced in ['.','-',',','!','?','(','—',')']:\r\n",
    "    corpus = corpus.replace(spaced, ' {0} '.format(spaced))\r\n",
    "\r\n",
    "print(f\"Number of tokens in corpus: {len(corpus)}\")\r\n",
    "# corpus[1000:1500]\r\n",
    "\r\n",
    "corpus_words = corpus.split(' ')\r\n",
    "corpus_words = [word for word in corpus_words if word != '']\r\n",
    "print(f\"Number of words in corpus: {len(corpus_words)}\")\r\n",
    "# corpus_words\r\n",
    "\r\n",
    "distinct_words = list(set(corpus_words))\r\n",
    "word_idx_dict = {word: i for i, word in enumerate(distinct_words)}\r\n",
    "distinct_words_count = len(list(set(corpus_words)))\r\n",
    "print(f\"Number of distinct words: {distinct_words_count}\")\r\n",
    "\r\n",
    "next_word_matrix = np.zeros([distinct_words_count,distinct_words_count])\r\n",
    "# word_idx_dict"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of tokens in corpus: 5701754\n",
      "Number of words in corpus: 1076054\n",
      "Number of distinct words: 39560\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "for i, word in enumerate(corpus_words[:-1]):\r\n",
    "    first_word_idx = word_idx_dict[word]\r\n",
    "    next_word_idx = word_idx_dict[corpus_words[i+1]]\r\n",
    "    next_word_matrix[first_word_idx][next_word_idx] +=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "def most_likely_word_after(aWord):\r\n",
    "    most_likely = next_word_matrix[word_idx_dict[aWord]].argmax()\r\n",
    "    return distinct_words[most_likely]\r\n",
    "\r\n",
    "\r\n",
    "def naive_chain(seed, length=25):\r\n",
    "    current_word = seed\r\n",
    "    sentence = seed\r\n",
    "    for _ in range(length):\r\n",
    "        sentence+=' '\r\n",
    "        next_word = most_likely_word_after(current_word)\r\n",
    "        sentence+=next_word\r\n",
    "        current_word = next_word\r\n",
    "    return sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "print(naive_chain('Hamlet'))\r\n",
    "print(naive_chain('the'))\r\n",
    "print(naive_chain('I'))\r\n",
    "print(naive_chain('he'))\r\n",
    "print(naive_chain('she'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hamlet . I am not , and the King . I am not , and the King . I am not , and the King .\n",
      "the King . I am not , and the King . I am not , and the King . I am not , and the King\n",
      "I am not , and the King . I am not , and the King . I am not , and the King . I am\n",
      "he is the King . I am not , and the King . I am not , and the King . I am not , and\n",
      "she is the King . I am not , and the King . I am not , and the King . I am not , and\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "import random\r\n",
    "from random import random \r\n",
    "\r\n",
    "def weighted_choice(objects, weights):\r\n",
    "    \"\"\" returns randomly an element from the sequence of 'objects', \r\n",
    "        the likelihood of the objects is weighted according \r\n",
    "        to the sequence of 'weights', i.e. percentages.\"\"\"\r\n",
    "\r\n",
    "    weights = np.array(weights, dtype=np.float64)\r\n",
    "    sum_of_weights = weights.sum()\r\n",
    "    # standardization:\r\n",
    "    np.multiply(weights, 1 / sum_of_weights, weights)\r\n",
    "    weights = weights.cumsum()\r\n",
    "    x = random()\r\n",
    "    for i in range(len(weights)):\r\n",
    "        if x < weights[i]:\r\n",
    "            return objects[i]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "\r\n",
    "from numpy.random import choice\r\n",
    "\r\n",
    "def sample_next_word_after(aWord, alpha = 0):\r\n",
    "    next_word_vector = next_word_matrix[word_idx_dict[aWord]] + alpha\r\n",
    "    likelihoods = next_word_vector/next_word_vector.sum()\r\n",
    "    return weighted_choice(distinct_words, likelihoods)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "print(sample_next_word_after('the'))\r\n",
    "print(sample_next_word_after('Hamlet'))\r\n",
    "print(sample_next_word_after('a'))\r\n",
    "print(sample_next_word_after('king'))\r\n",
    "print(sample_next_word_after('house'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lady\n",
      ",\n",
      "lion\n",
      "of\n",
      "Be\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def stochastic_chain_1(seed, length=15):\r\n",
    "    current_word = seed\r\n",
    "    sentence = seed\r\n",
    "    for _ in range(length):\r\n",
    "        sentence+=' '\r\n",
    "        next_word = sample_next_word_after(current_word)\r\n",
    "        sentence+=next_word\r\n",
    "        current_word = next_word\r\n",
    "    return sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "print(stochastic_chain_1('Hamlet'))\r\n",
    "print(stochastic_chain_1('King'))\r\n",
    "print(stochastic_chain_1('Romeo'))\r\n",
    "print(stochastic_chain_1('Ophelia'))\r\n",
    "print(stochastic_chain_1('Time'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hamlet give thee breathe my house doth the kissing my steed; But that's foul oyster of\n",
      "King being down what to the devil , by surfeit is no more than he hath\n",
      "Romeo , at you ? BIONDELLO . How likes me . We made men die our\n",
      "Ophelia ! Osr . KEEPER . Tell me of your crafts ! We may spur was\n",
      "Time try for he think you frame the buried , I will needs must be ransom\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "k = 2\r\n",
    "sets_of_k_words = [ ' '.join(corpus_words[i:i+k]) for i, _ in enumerate(corpus_words[:-k]) ]\r\n",
    "\r\n",
    "print([len(list(set(sets_of_k_words))),\r\n",
    "    len(sets_of_k_words)])\r\n",
    "\r\n",
    "from scipy.sparse import dok_matrix\r\n",
    "\r\n",
    "sets_count = len(list(set(sets_of_k_words)))\r\n",
    "next_after_k_words_matrix = dok_matrix((sets_count, len(distinct_words)))\r\n",
    "print(next_after_k_words_matrix.shape)\r\n",
    "\r\n",
    "\r\n",
    "distinct_sets_of_k_words = list(set(sets_of_k_words))\r\n",
    "k_words_idx_dict = {word: i for i, word in enumerate(distinct_sets_of_k_words)}\r\n",
    "distinct_k_words_count = len(list(set(sets_of_k_words)))\r\n",
    "print(len(sets_of_k_words))\r\n",
    "\r\n",
    "for i, word in enumerate(sets_of_k_words[:-k]):\r\n",
    "    word_sequence_idx = k_words_idx_dict[word]\r\n",
    "    next_word_idx = word_idx_dict[corpus_words[i+k]]\r\n",
    "    next_after_k_words_matrix[word_sequence_idx, next_word_idx] +=1\r\n",
    "\r\n",
    "\r\n",
    "from numpy.random import choice\r\n",
    "def sample_next_word_after_sequence_2(word_sequence, alpha = 0):\r\n",
    "    next_word_vector = next_after_k_words_matrix[k_words_idx_dict[word_sequence]] + alpha\r\n",
    "    likelihoods = next_word_vector/next_word_vector.sum()\r\n",
    "    return weighted_choice(distinct_words, likelihoods.toarray())\r\n",
    "\r\n",
    "\r\n",
    "def stochastic_chain_2(seed, chain_length=15, seed_length=2):\r\n",
    "    current_words = seed.split(' ')\r\n",
    "    if len(current_words) != seed_length:\r\n",
    "        raise ValueError(f'wrong number of words, expected {seed_length}')\r\n",
    "    sentence = seed\r\n",
    "\r\n",
    "    for _ in range(chain_length):\r\n",
    "        sentence+=' '\r\n",
    "        next_word = sample_next_word_after_sequence_2(' '.join(current_words))\r\n",
    "        sentence+=next_word\r\n",
    "        current_words = current_words[1:]+[next_word]\r\n",
    "    return sentence"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[347560, 1076052]\n",
      "(347560, 39560)\n",
      "1076052\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "print(sample_next_word_after('a'))\r\n",
    "print(sample_next_word_after_sequence_2('a house'))\r\n",
    "print(sample_next_word_after('to'))\r\n",
    "print(sample_next_word_after_sequence_2('to be'))\r\n",
    "print(sample_next_word_after('prince'))\r\n",
    "print(sample_next_word_after_sequence_2('have been'))\r\n",
    "print(stochastic_chain_2('a house'))\r\n",
    "print(stochastic_chain_2('to be'))\r\n",
    "print(stochastic_chain_2('have been'))\r\n",
    "print(stochastic_chain_2('Hamlet\\'s Father'))\r\n",
    "print(stochastic_chain_2('The housekeeper'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "blessed\n",
      "broke\n",
      "leave\n",
      "his\n",
      ",\n",
      "at\n",
      "a house . Mer . Any thing . Re - enter three citizens more Here come our\n",
      "to be found so , though it have a hempen caudle then , the other door PETER\n",
      "have been talk'd of more bastard children than war's a destroyer of men . SECOND GENTLEMAN .\n",
      "Hamlet's Father . Lords , use such vigilance As when thy father to my strong intent ,\n",
      "The housekeeper , the King . POLIXENES . How much salt water , though unfinish'd , yet\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "k = 5\r\n",
    "sets_of_k_words = [ ' '.join(corpus_words[i:i+k]) for i, _ in enumerate(corpus_words[:-k]) ]\r\n",
    "\r\n",
    "print([len(list(set(sets_of_k_words))),\r\n",
    "    len(sets_of_k_words)])\r\n",
    "\r\n",
    "from scipy.sparse import dok_matrix\r\n",
    "\r\n",
    "sets_count = len(list(set(sets_of_k_words)))\r\n",
    "next_after_k_words_matrix = dok_matrix((sets_count, len(distinct_words)))\r\n",
    "print(next_after_k_words_matrix.shape)\r\n",
    "\r\n",
    "\r\n",
    "distinct_sets_of_k_words = list(set(sets_of_k_words))\r\n",
    "k_words_idx_dict = {word: i for i, word in enumerate(distinct_sets_of_k_words)}\r\n",
    "distinct_k_words_count = len(list(set(sets_of_k_words)))\r\n",
    "print(len(sets_of_k_words))\r\n",
    "\r\n",
    "for i, word in enumerate(sets_of_k_words[:-k]):\r\n",
    "    word_sequence_idx = k_words_idx_dict[word]\r\n",
    "    next_word_idx = word_idx_dict[corpus_words[i+k]]\r\n",
    "    next_after_k_words_matrix[word_sequence_idx, next_word_idx] +=1\r\n",
    "\r\n",
    "\r\n",
    "from numpy.random import choice\r\n",
    "def sample_next_word_after_sequence_5(word_sequence, alpha = 0):\r\n",
    "    next_word_vector = next_after_k_words_matrix[k_words_idx_dict[word_sequence]] + alpha\r\n",
    "    likelihoods = next_word_vector/next_word_vector.sum()\r\n",
    "    return weighted_choice(distinct_words, likelihoods.toarray())\r\n",
    "\r\n",
    "\r\n",
    "def stochastic_chain_5(seed, chain_length=30, seed_length=5):\r\n",
    "    current_words = seed.split(' ')\r\n",
    "    if len(current_words) != seed_length:\r\n",
    "        raise ValueError(f'wrong number of words, expected {seed_length}')\r\n",
    "    sentence = seed\r\n",
    "\r\n",
    "    for _ in range(chain_length):\r\n",
    "        sentence+=' '\r\n",
    "        next_word = sample_next_word_after_sequence_2(' '.join(current_words))\r\n",
    "        sentence+=next_word\r\n",
    "        current_words = current_words[1:]+[next_word]\r\n",
    "    return sentence"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1049474, 1076049]\n",
      "(1049474, 39560)\n",
      "1076049\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "print(stochastic_chain_5('by the name of dogs'))\r\n",
    "print(stochastic_chain_5('you found them in mine'))\r\n",
    "print(stochastic_chain_5('Making a famine where abundance'))\r\n",
    "print(stochastic_chain_5('Laertes and his sister Ophelia'))\r\n",
    "print(stochastic_chain_5('Good Hamlet , cast thy'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "by the name of dogs . The valued file Distinguishes the swift , the slow , the subtle , The housekeeper , the hunter , every one According to the gift which bounteous nature Hath\n",
      "you found them in mine honesty . When , for some trifling present , you have bid me Return so much , I have shook my head and wept; Yea , 'gainst th' authority of\n",
      "Making a famine where abundance lies , Thy self thy foe , to thy sweet self too cruel: Thou that art now the world's fresh ornament , And only herald to the gaudy spring ,\n",
      "Laertes and his sister Ophelia , [Voltemand , Cornelius , ] Lords Attendant . King . Though yet of Hamlet our dear brother's death The memory be green , and that it us befitted To\n",
      "Good Hamlet , cast thy nighted colour off , And let thine eye look like a friend on Denmark . Do not for ever with thy vailed lids Seek for thy noble father in the\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (system)"
  },
  "interpreter": {
   "hash": "d4be04134da666ba417300a0c020abeb8478be2ead96ebfe9eeadc929de095c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}